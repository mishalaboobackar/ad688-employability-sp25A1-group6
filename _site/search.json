[
  {
    "objectID": "data_cleaning.html",
    "href": "data_cleaning.html",
    "title": "Data Cleaning & Preprocessing",
    "section": "",
    "text": "This notebook performs data cleaning on the Lightcast job postings dataset, preparing it for exploratory analysis and machine learning models.\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport missingno as msno\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndf = pd.read_csv('data/lightcast_job_postings.csv', \n                 low_memory=False,\n                 dtype={'ID': str}) \n\nprint(f\"Original dataset shape: {df.shape}\")\n\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)  \npd.set_option('display.width', None)\ndisplay(df.head())\n\n\nOriginal dataset shape: (72498, 131)\n\n\n\n\n\n\n\n\n\nID\nLAST_UPDATED_DATE\nLAST_UPDATED_TIMESTAMP\nDUPLICATES\nPOSTED\nEXPIRED\nDURATION\nSOURCE_TYPES\nSOURCES\nURL\nACTIVE_URLS\nACTIVE_SOURCES_INFO\nTITLE_RAW\nBODY\nMODELED_EXPIRED\nMODELED_DURATION\nCOMPANY\nCOMPANY_NAME\nCOMPANY_RAW\nCOMPANY_IS_STAFFING\nEDUCATION_LEVELS\nEDUCATION_LEVELS_NAME\nMIN_EDULEVELS\nMIN_EDULEVELS_NAME\nMAX_EDULEVELS\nMAX_EDULEVELS_NAME\nEMPLOYMENT_TYPE\nEMPLOYMENT_TYPE_NAME\nMIN_YEARS_EXPERIENCE\nMAX_YEARS_EXPERIENCE\nIS_INTERNSHIP\nSALARY\nREMOTE_TYPE\nREMOTE_TYPE_NAME\nORIGINAL_PAY_PERIOD\nSALARY_TO\nSALARY_FROM\nLOCATION\nCITY\nCITY_NAME\nCOUNTY\nCOUNTY_NAME\nMSA\nMSA_NAME\nSTATE\nSTATE_NAME\nCOUNTY_OUTGOING\nCOUNTY_NAME_OUTGOING\nCOUNTY_INCOMING\nCOUNTY_NAME_INCOMING\nMSA_OUTGOING\nMSA_NAME_OUTGOING\nMSA_INCOMING\nMSA_NAME_INCOMING\nNAICS2\nNAICS2_NAME\nNAICS3\nNAICS3_NAME\nNAICS4\nNAICS4_NAME\nNAICS5\nNAICS5_NAME\nNAICS6\nNAICS6_NAME\nTITLE\nTITLE_NAME\nTITLE_CLEAN\nSKILLS\nSKILLS_NAME\nSPECIALIZED_SKILLS\nSPECIALIZED_SKILLS_NAME\nCERTIFICATIONS\nCERTIFICATIONS_NAME\nCOMMON_SKILLS\nCOMMON_SKILLS_NAME\nSOFTWARE_SKILLS\nSOFTWARE_SKILLS_NAME\nONET\nONET_NAME\nONET_2019\nONET_2019_NAME\nCIP6\nCIP6_NAME\nCIP4\nCIP4_NAME\nCIP2\nCIP2_NAME\nSOC_2021_2\nSOC_2021_2_NAME\nSOC_2021_3\nSOC_2021_3_NAME\nSOC_2021_4\nSOC_2021_4_NAME\nSOC_2021_5\nSOC_2021_5_NAME\nLOT_CAREER_AREA\nLOT_CAREER_AREA_NAME\nLOT_OCCUPATION\nLOT_OCCUPATION_NAME\nLOT_SPECIALIZED_OCCUPATION\nLOT_SPECIALIZED_OCCUPATION_NAME\nLOT_OCCUPATION_GROUP\nLOT_OCCUPATION_GROUP_NAME\nLOT_V6_SPECIALIZED_OCCUPATION\nLOT_V6_SPECIALIZED_OCCUPATION_NAME\nLOT_V6_OCCUPATION\nLOT_V6_OCCUPATION_NAME\nLOT_V6_OCCUPATION_GROUP\nLOT_V6_OCCUPATION_GROUP_NAME\nLOT_V6_CAREER_AREA\nLOT_V6_CAREER_AREA_NAME\nSOC_2\nSOC_2_NAME\nSOC_3\nSOC_3_NAME\nSOC_4\nSOC_4_NAME\nSOC_5\nSOC_5_NAME\nLIGHTCAST_SECTORS\nLIGHTCAST_SECTORS_NAME\nNAICS_2022_2\nNAICS_2022_2_NAME\nNAICS_2022_3\nNAICS_2022_3_NAME\nNAICS_2022_4\nNAICS_2022_4_NAME\nNAICS_2022_5\nNAICS_2022_5_NAME\nNAICS_2022_6\nNAICS_2022_6_NAME\n\n\n\n\n0\n1f57d95acf4dc67ed2819eb12f049f6a5c11782c\n9/6/2024\n2024-09-06 20:32:57.352 Z\n0.0\n6/2/2024\n6/8/2024\n6.0\n[\\n \"Company\"\\n]\n[\\n \"brassring.com\"\\n]\n[\\n \"https://sjobs.brassring.com/TGnewUI/Sear...\n[]\nNaN\nEnterprise Analyst (II-III)\n31-May-2024\\n\\nEnterprise Analyst (II-III)\\n\\n...\n6/8/2024\n6.0\n894731.0\nMurphy USA\nMurphy USA\nFalse\n[\\n 2\\n]\n[\\n \"Bachelor's degree\"\\n]\n2.0\nBachelor's degree\nNaN\nNaN\n1.0\nFull-time (&gt; 32 hours)\n2.0\n2.0\nFalse\nNaN\n0.0\n[None]\nNaN\nNaN\nNaN\n{\\n \"lat\": 33.20763,\\n \"lon\": -92.6662674\\n}\nRWwgRG9yYWRvLCBBUg==\nEl Dorado, AR\n5139.0\nUnion, AR\n20980.0\nEl Dorado, AR\n5.0\nArkansas\n5139.0\nUnion, AR\n5139.0\nUnion, AR\n20980.0\nEl Dorado, AR\n20980.0\nEl Dorado, AR\n44.0\nRetail Trade\n441.0\nMotor Vehicle and Parts Dealers\n4413.0\nAutomotive Parts, Accessories, and Tire Retailers\n44133.0\nAutomotive Parts and Accessories Retailers\n441330.0\nAutomotive Parts and Accessories Retailers\nET29C073C03D1F86B4\nEnterprise Analysts\nenterprise analyst ii iii\n[\\n \"KS126DB6T061MHD7RTGQ\",\\n \"KS126706DPFD3...\n[\\n \"Merchandising\",\\n \"Mathematics\",\\n \"Pr...\n[\\n \"KS126DB6T061MHD7RTGQ\",\\n \"KS128006L3V0H...\n[\\n \"Merchandising\",\\n \"Predictive Modeling\"...\n[]\n[]\n[\\n \"KS126706DPFD3354M7YK\",\\n \"KS1280B68GD79...\n[\\n \"Mathematics\",\\n \"Presentations\",\\n \"Re...\n[\\n \"KS440W865GC4VRBW6LJP\",\\n \"KS13USA80NE38...\n[\\n \"SQL (Programming Language)\",\\n \"Power B...\n15-2051.01\nBusiness Intelligence Analysts\n15-2051.01\nBusiness Intelligence Analysts\n[\\n \"45.0601\",\\n \"27.0101\"\\n]\n[\\n \"Economics, General\",\\n \"Mathematics, Ge...\n[\\n \"45.06\",\\n \"27.01\"\\n]\n[\\n \"Economics\",\\n \"Mathematics\"\\n]\n[\\n \"45\",\\n \"27\"\\n]\n[\\n \"Social Sciences\",\\n \"Mathematics and St...\n15-0000\nComputer and Mathematical Occupations\n15-2000\nMathematical Science Occupations\n15-2050\nData Scientists\n15-2051\nData Scientists\n23.0\nInformation Technology and Computer Science\n231010.0\nBusiness Intelligence Analyst\n23101011.0\nGeneral ERP Analyst / Consultant\n2310.0\nBusiness Intelligence\n23101011.0\nGeneral ERP Analyst / Consultant\n231010.0\nBusiness Intelligence Analyst\n2310.0\nBusiness Intelligence\n23.0\nInformation Technology and Computer Science\n15-0000\nComputer and Mathematical Occupations\n15-2000\nMathematical Science Occupations\n15-2050\nData Scientists\n15-2051\nData Scientists\n[\\n 7\\n]\n[\\n \"Artificial Intelligence\"\\n]\n44.0\nRetail Trade\n441.0\nMotor Vehicle and Parts Dealers\n4413.0\nAutomotive Parts, Accessories, and Tire Retailers\n44133.0\nAutomotive Parts and Accessories Retailers\n441330.0\nAutomotive Parts and Accessories Retailers\n\n\n1\n0cb072af26757b6c4ea9464472a50a443af681ac\n8/2/2024\n2024-08-02 17:08:58.838 Z\n0.0\n6/2/2024\n8/1/2024\nNaN\n[\\n \"Job Board\"\\n]\n[\\n \"maine.gov\"\\n]\n[\\n \"https://joblink.maine.gov/jobs/1085740\"\\n]\n[]\nNaN\nOracle Consultant - Reports (3592)\nOracle Consultant - Reports (3592)\\n\\nat SMX i...\n8/1/2024\nNaN\n133098.0\nSmx Corporation Limited\nSMX\nTrue\n[\\n 99\\n]\n[\\n \"No Education Listed\"\\n]\n99.0\nNo Education Listed\nNaN\nNaN\n1.0\nFull-time (&gt; 32 hours)\n3.0\n3.0\nFalse\nNaN\n1.0\nRemote\nNaN\nNaN\nNaN\n{\\n \"lat\": 44.3106241,\\n \"lon\": -69.7794897\\n}\nQXVndXN0YSwgTUU=\nAugusta, ME\n23011.0\nKennebec, ME\n12300.0\nAugusta-Waterville, ME\n23.0\nMaine\n23011.0\nKennebec, ME\n23011.0\nKennebec, ME\n12300.0\nAugusta-Waterville, ME\n12300.0\nAugusta-Waterville, ME\n56.0\nAdministrative and Support and Waste Managemen...\n561.0\nAdministrative and Support Services\n5613.0\nEmployment Services\n56132.0\nTemporary Help Services\n561320.0\nTemporary Help Services\nET21DDA63780A7DC09\nOracle Consultants\noracle consultant reports\n[\\n \"KS122626T550SLQ7QZ1C\",\\n \"KS123YJ6KVWC9...\n[\\n \"Procurement\",\\n \"Financial Statements\",...\n[\\n \"KS122626T550SLQ7QZ1C\",\\n \"KS123YJ6KVWC9...\n[\\n \"Procurement\",\\n \"Financial Statements\",...\n[]\n[]\n[]\n[]\n[\\n \"BGSBF3F508F7F46312E3\",\\n \"ESEA839CED378...\n[\\n \"Oracle Business Intelligence (BI) / OBIA...\n15-2051.01\nBusiness Intelligence Analysts\n15-2051.01\nBusiness Intelligence Analysts\n[]\n[]\n[]\n[]\n[]\n[]\n15-0000\nComputer and Mathematical Occupations\n15-2000\nMathematical Science Occupations\n15-2050\nData Scientists\n15-2051\nData Scientists\n23.0\nInformation Technology and Computer Science\n231010.0\nBusiness Intelligence Analyst\n23101012.0\nOracle Consultant / Analyst\n2310.0\nBusiness Intelligence\n23101012.0\nOracle Consultant / Analyst\n231010.0\nBusiness Intelligence Analyst\n2310.0\nBusiness Intelligence\n23.0\nInformation Technology and Computer Science\n15-0000\nComputer and Mathematical Occupations\n15-2000\nMathematical Science Occupations\n15-2050\nData Scientists\n15-2051\nData Scientists\nNaN\nNaN\n56.0\nAdministrative and Support and Waste Managemen...\n561.0\nAdministrative and Support Services\n5613.0\nEmployment Services\n56132.0\nTemporary Help Services\n561320.0\nTemporary Help Services\n\n\n2\n85318b12b3331fa490d32ad014379df01855c557\n9/6/2024\n2024-09-06 20:32:57.352 Z\n1.0\n6/2/2024\n7/7/2024\n35.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\n[\\n \"https://dejobs.org/dallas-tx/data-analys...\n[]\nNaN\nData Analyst\nTaking care of people is at the heart of every...\n6/10/2024\n8.0\n39063746.0\nSedgwick\nSedgwick\nFalse\n[\\n 2\\n]\n[\\n \"Bachelor's degree\"\\n]\n2.0\nBachelor's degree\nNaN\nNaN\n1.0\nFull-time (&gt; 32 hours)\n5.0\nNaN\nFalse\nNaN\n0.0\n[None]\nNaN\nNaN\nNaN\n{\\n \"lat\": 32.7766642,\\n \"lon\": -96.7969879\\n}\nRGFsbGFzLCBUWA==\nDallas, TX\n48113.0\nDallas, TX\n19100.0\nDallas-Fort Worth-Arlington, TX\n48.0\nTexas\n48113.0\nDallas, TX\n48113.0\nDallas, TX\n19100.0\nDallas-Fort Worth-Arlington, TX\n19100.0\nDallas-Fort Worth-Arlington, TX\n52.0\nFinance and Insurance\n524.0\nInsurance Carriers and Related Activities\n5242.0\nAgencies, Brokerages, and Other Insurance Rela...\n52429.0\nOther Insurance Related Activities\n524291.0\nClaims Adjusting\nET3037E0C947A02404\nData Analysts\ndata analyst\n[\\n \"KS1218W78FGVPVP2KXPX\",\\n \"ESF3939CE1F80...\n[\\n \"Management\",\\n \"Exception Reporting\",\\n...\n[\\n \"ESF3939CE1F80C10C327\",\\n \"KS120GV6C72JM...\n[\\n \"Exception Reporting\",\\n \"Data Analysis\"...\n[\\n \"KS683TN76T77DQDVBZ1B\"\\n]\n[\\n \"Security Clearance\"\\n]\n[\\n \"KS1218W78FGVPVP2KXPX\",\\n \"BGS1ADAA36DB6...\n[\\n \"Management\",\\n \"Report Writing\",\\n \"In...\n[\\n \"KS126HY6YLTB9R7XJC4Z\"\\n]\n[\\n \"Microsoft Office\"\\n]\n15-2051.01\nBusiness Intelligence Analysts\n15-2051.01\nBusiness Intelligence Analysts\n[]\n[]\n[]\n[]\n[]\n[]\n15-0000\nComputer and Mathematical Occupations\n15-2000\nMathematical Science Occupations\n15-2050\nData Scientists\n15-2051\nData Scientists\n23.0\nInformation Technology and Computer Science\n231113.0\nData / Data Mining Analyst\n23111310.0\nData Analyst\n2311.0\nData Analysis and Mathematics\n23111310.0\nData Analyst\n231113.0\nData / Data Mining Analyst\n2311.0\nData Analysis and Mathematics\n23.0\nInformation Technology and Computer Science\n15-0000\nComputer and Mathematical Occupations\n15-2000\nMathematical Science Occupations\n15-2050\nData Scientists\n15-2051\nData Scientists\nNaN\nNaN\n52.0\nFinance and Insurance\n524.0\nInsurance Carriers and Related Activities\n5242.0\nAgencies, Brokerages, and Other Insurance Rela...\n52429.0\nOther Insurance Related Activities\n524291.0\nClaims Adjusting\n\n\n3\n1b5c3941e54a1889ef4f8ae55b401a550708a310\n9/6/2024\n2024-09-06 20:32:57.352 Z\n1.0\n6/2/2024\n7/20/2024\n48.0\n[\\n \"Job Board\"\\n]\n[\\n \"disabledperson.com\",\\n \"dejobs.org\"\\n]\n[\\n \"https://www.disabledperson.com/jobs/5948...\n[]\nNaN\nSr. Lead Data Mgmt. Analyst - SAS Product Owner\nAbout this role:\\n\\nWells Fargo is looking for...\n6/12/2024\n10.0\n37615159.0\nWells Fargo\nWells Fargo\nFalse\n[\\n 99\\n]\n[\\n \"No Education Listed\"\\n]\n99.0\nNo Education Listed\nNaN\nNaN\n1.0\nFull-time (&gt; 32 hours)\n3.0\nNaN\nFalse\nNaN\n0.0\n[None]\nNaN\nNaN\nNaN\n{\\n \"lat\": 33.4483771,\\n \"lon\": -112.0740373\\n}\nUGhvZW5peCwgQVo=\nPhoenix, AZ\n4013.0\nMaricopa, AZ\n38060.0\nPhoenix-Mesa-Chandler, AZ\n4.0\nArizona\n4013.0\nMaricopa, AZ\n4013.0\nMaricopa, AZ\n38060.0\nPhoenix-Mesa-Chandler, AZ\n38060.0\nPhoenix-Mesa-Chandler, AZ\n52.0\nFinance and Insurance\n522.0\nCredit Intermediation and Related Activities\n5221.0\nDepository Credit Intermediation\n52211.0\nCommercial Banking\n522110.0\nCommercial Banking\nET2114E0404BA30075\nManagement Analysts\nsr lead data mgmt analyst sas product owner\n[\\n \"KS123QX62QYTC4JF38H8\",\\n \"KS7G6NP6R6L1H...\n[\\n \"Exit Strategies\",\\n \"Reliability\",\\n \"...\n[\\n \"KS123QX62QYTC4JF38H8\",\\n \"KS441PQ64HT13...\n[\\n \"Exit Strategies\",\\n \"User Story\",\\n \"H...\n[]\n[]\n[\\n \"KS7G6NP6R6L1H1SKFTSY\",\\n \"KS1218W78FGVP...\n[\\n \"Reliability\",\\n \"Management\",\\n \"Strat...\n[\\n \"KS4409D76NW1S5LNCL18\",\\n \"ESC7869CF7378...\n[\\n \"SAS (Software)\",\\n \"Google Cloud Platfo...\n15-2051.01\nBusiness Intelligence Analysts\n15-2051.01\nBusiness Intelligence Analysts\n[]\n[]\n[]\n[]\n[]\n[]\n15-0000\nComputer and Mathematical Occupations\n15-2000\nMathematical Science Occupations\n15-2050\nData Scientists\n15-2051\nData Scientists\n23.0\nInformation Technology and Computer Science\n231113.0\nData / Data Mining Analyst\n23111310.0\nData Analyst\n2311.0\nData Analysis and Mathematics\n23111310.0\nData Analyst\n231113.0\nData / Data Mining Analyst\n2311.0\nData Analysis and Mathematics\n23.0\nInformation Technology and Computer Science\n15-0000\nComputer and Mathematical Occupations\n15-2000\nMathematical Science Occupations\n15-2050\nData Scientists\n15-2051\nData Scientists\n[\\n 6\\n]\n[\\n \"Data Privacy/Protection\"\\n]\n52.0\nFinance and Insurance\n522.0\nCredit Intermediation and Related Activities\n5221.0\nDepository Credit Intermediation\n52211.0\nCommercial Banking\n522110.0\nCommercial Banking\n\n\n4\ncb5ca25f02bdf25c13edfede7931508bfd9e858f\n6/19/2024\n2024-06-19 07:00:00.000 Z\n0.0\n6/2/2024\n6/17/2024\n15.0\n[\\n \"FreeJobBoard\"\\n]\n[\\n \"craigslist.org\"\\n]\n[\\n \"https://modesto.craigslist.org/sls/77475...\n[]\nNaN\nComisiones de $1000 - $3000 por semana... Comi...\nComisiones de $1000 - $3000 por semana... Comi...\n6/17/2024\n15.0\n0.0\nUnclassified\nLH/GM\nFalse\n[\\n 99\\n]\n[\\n \"No Education Listed\"\\n]\n99.0\nNo Education Listed\nNaN\nNaN\n3.0\nPart-time / full-time\nNaN\nNaN\nFalse\n92500.0\n0.0\n[None]\nyear\n150000.0\n35000.0\n{\\n \"lat\": 37.6392595,\\n \"lon\": -120.9970014\\n}\nTW9kZXN0bywgQ0E=\nModesto, CA\n6099.0\nStanislaus, CA\n33700.0\nModesto, CA\n6.0\nCalifornia\n6099.0\nStanislaus, CA\n6099.0\nStanislaus, CA\n33700.0\nModesto, CA\n33700.0\nModesto, CA\n99.0\nUnclassified Industry\n999.0\nUnclassified Industry\n9999.0\nUnclassified Industry\n99999.0\nUnclassified Industry\n999999.0\nUnclassified Industry\nET0000000000000000\nUnclassified\ncomisiones de por semana comiensa rapido\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n[]\n15-2051.01\nBusiness Intelligence Analysts\n15-2051.01\nBusiness Intelligence Analysts\n[]\n[]\n[]\n[]\n[]\n[]\n15-0000\nComputer and Mathematical Occupations\n15-2000\nMathematical Science Occupations\n15-2050\nData Scientists\n15-2051\nData Scientists\n23.0\nInformation Technology and Computer Science\n231010.0\nBusiness Intelligence Analyst\n23101012.0\nOracle Consultant / Analyst\n2310.0\nBusiness Intelligence\n23101012.0\nOracle Consultant / Analyst\n231010.0\nBusiness Intelligence Analyst\n2310.0\nBusiness Intelligence\n23.0\nInformation Technology and Computer Science\n15-0000\nComputer and Mathematical Occupations\n15-2000\nMathematical Science Occupations\n15-2050\nData Scientists\n15-2051\nData Scientists\nNaN\nNaN\n99.0\nUnclassified Industry\n999.0\nUnclassified Industry\n9999.0\nUnclassified Industry\n99999.0\nUnclassified Industry\n999999.0\nUnclassified Industry"
  },
  {
    "objectID": "data_cleaning.html#select-relevant-columns",
    "href": "data_cleaning.html#select-relevant-columns",
    "title": "Data Cleaning & Preprocessing",
    "section": "1. Select Relevant Columns",
    "text": "1. Select Relevant Columns\n\n\nCode\ncolumns_to_keep = [\n    'POSTED', 'EXPIRED','TITLE_NAME', 'COMPANY_NAME','SOURCE_TYPES', 'COMPANY_IS_STAFFING', \n    'SALARY', 'SALARY_FROM', 'SALARY_TO','STATE_NAME', 'CITY_NAME','REMOTE_TYPE_NAME', \n    'EMPLOYMENT_TYPE_NAME','MIN_YEARS_EXPERIENCE','MIN_EDULEVELS_NAME','SKILLS_NAME', 'SOFTWARE_SKILLS_NAME',\n    'LOT_V6_OCCUPATION_NAME','NAICS_2022_2_NAME'\n]\ncolumns_to_keep = [col for col in columns_to_keep if col in df.columns]\ndf = df[columns_to_keep].copy()\n\nprint(f\"Shape after column selection: {df.shape}\")\nprint(f\"\\nColumns kept ({len(df.columns)}):\")\nprint(df.columns.tolist())\n\n\nShape after column selection: (72498, 19)\n\nColumns kept (19):\n['POSTED', 'EXPIRED', 'TITLE_NAME', 'COMPANY_NAME', 'SOURCE_TYPES', 'COMPANY_IS_STAFFING', 'SALARY', 'SALARY_FROM', 'SALARY_TO', 'STATE_NAME', 'CITY_NAME', 'REMOTE_TYPE_NAME', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MIN_EDULEVELS_NAME', 'SKILLS_NAME', 'SOFTWARE_SKILLS_NAME', 'LOT_V6_OCCUPATION_NAME', 'NAICS_2022_2_NAME']"
  },
  {
    "objectID": "data_cleaning.html#create-duration-feature",
    "href": "data_cleaning.html#create-duration-feature",
    "title": "Data Cleaning & Preprocessing",
    "section": "2. Create Duration Feature",
    "text": "2. Create Duration Feature\nDuration = EXPIRED - POSTED (in days)\n\n\nCode\ndf = df.dropna(subset=['EXPIRED'])\ndf['POSTED'] = pd.to_datetime(df['POSTED'], errors='coerce')\ndf['EXPIRED'] = pd.to_datetime(df['EXPIRED'], errors='coerce')\n\ndf['DURATION'] = (df['EXPIRED'] - df['POSTED']).dt.days\n\nprint(\"Duration statistics:\")\nprint(df['DURATION'].describe())\n\ndf.drop(columns=['EXPIRED'], inplace=True)\n\nprint(f\"\\nShape: {df.shape}\")\n\n\nDuration statistics:\ncount    64654.000000\nmean        35.296811\nstd         23.961129\nmin          0.000000\n25%         14.000000\n50%         31.000000\n75%         60.000000\nmax        119.000000\nName: DURATION, dtype: float64\n\nShape: (64654, 19)"
  },
  {
    "objectID": "data_cleaning.html#explore-lot_v6_occupation_name-for-filtering",
    "href": "data_cleaning.html#explore-lot_v6_occupation_name-for-filtering",
    "title": "Data Cleaning & Preprocessing",
    "section": "3. Explore LOT_V6_OCCUPATION_NAME for Filtering",
    "text": "3. Explore LOT_V6_OCCUPATION_NAME for Filtering\nUsing LOT_V6_OCCUPATION_NAME provides more accurate job classification than TITLE_NAME.\n\n\nCode\nprint(\"LOT_V6_OCCUPATION_NAME value counts:\\n\")\nprint(df['LOT_V6_OCCUPATION_NAME'].value_counts())\n\n\nLOT_V6_OCCUPATION_NAME value counts:\n\nLOT_V6_OCCUPATION_NAME\nData / Data Mining Analyst                                              26809\nBusiness Intelligence Analyst                                           26550\nComputer Systems Engineer / Architect                                    7188\nBusiness / Management Analyst                                            3729\nClinical Analyst / Clinical Documentation and Improvement Specialist      228\nMarket Research Analyst                                                   132\nName: count, dtype: int64\n\n\n\n\nCode\noccupations_to_keep = [\n    'Data / Data Mining Analyst',\n    'Business Intelligence Analyst',\n    'Business / Management Analyst',\n    'Market Research Analyst'\n\n]\ndf = df[df['LOT_V6_OCCUPATION_NAME'].isin(occupations_to_keep)].copy()\n\nprint(f\"Shape after filtering: {df.shape}\")\nprint(f\"\\nOccupations kept:\")\nprint(df['LOT_V6_OCCUPATION_NAME'].value_counts())\n\n\nShape after filtering: (57220, 19)\n\nOccupations kept:\nLOT_V6_OCCUPATION_NAME\nData / Data Mining Analyst       26809\nBusiness Intelligence Analyst    26550\nBusiness / Management Analyst     3729\nMarket Research Analyst            132\nName: count, dtype: int64"
  },
  {
    "objectID": "data_cleaning.html#clean-string-formatting",
    "href": "data_cleaning.html#clean-string-formatting",
    "title": "Data Cleaning & Preprocessing",
    "section": "4. Clean String Formatting",
    "text": "4. Clean String Formatting\nRemove JSON-like formatting: [\\n  \"value\"\\n] → value1, value2\nAlso remove empty arrays [].\n\n\nCode\ndef clean_json_string(value):\n  \n    if pd.isna(value):\n        return np.nan\n    \n    if not isinstance(value, str):\n        return value\n    \n    value = value.strip()\n    \n    # Handle empty list or [None]\n    if value in ['[]', '[None]', '[\\n]', '', '[ ]']:\n        return np.nan\n    \n    # Check if it's a JSON-like array\n    if value.startswith('[') and value.endswith(']'):\n        # Remove brackets\n        cleaned = value[1:-1]\n        \n        # Remove \\n, extra spaces, quotes\n        cleaned = re.sub(r'\\\\n', '', cleaned)\n        cleaned = re.sub(r'\\n', '', cleaned)\n        cleaned = re.sub(r'\"', '', cleaned)\n        \n        # Split by comma and clean each item\n        items = [item.strip() for item in cleaned.split(',') if item.strip()]\n        \n        if not items:\n            return np.nan\n        \n        return ', '.join(items)\n    \n    return value.strip()\n\n\n# Columns to clean\njson_columns = [\n    'SKILLS_NAME', \n    'SOFTWARE_SKILLS_NAME',\n    'SOURCE_TYPES',\n    'REMOTE_TYPE_NAME',\n    'EMPLOYMENT_TYPE_NAME',\n    'MIN_EDULEVELS_NAME'\n]\n\n# Apply cleaning\nfor col in json_columns:\n    if col in df.columns:\n        print(f\"Cleaning: {col}\")\n        df[col] = df[col].apply(clean_json_string)\n\n\n\nCleaning: SKILLS_NAME\nCleaning: SOFTWARE_SKILLS_NAME\nCleaning: SOURCE_TYPES\nCleaning: REMOTE_TYPE_NAME\nCleaning: EMPLOYMENT_TYPE_NAME\nCleaning: MIN_EDULEVELS_NAME"
  },
  {
    "objectID": "data_cleaning.html#handling-missing-values",
    "href": "data_cleaning.html#handling-missing-values",
    "title": "Data Cleaning & Preprocessing",
    "section": "5. Handling Missing Values",
    "text": "5. Handling Missing Values\n\n5.1 Salary\n\n\nCode\n\nprint(\"Missing salary values BEFORE imputation:\")\nprint(f\"  SALARY: {df['SALARY'].isna().sum()}\")\nprint(f\"  SALARY_FROM: {df['SALARY_FROM'].isna().sum()}\")\nprint(f\"  SALARY_TO: {df['SALARY_TO'].isna().sum()}\")\n\nsalary_cols = ['SALARY', 'SALARY_FROM', 'SALARY_TO']\n\nfor col in salary_cols:\n    if col in df.columns:\n        median_by_occupation = df.groupby('LOT_V6_OCCUPATION_NAME')[col].transform('median')\n        \n        df[col] = df[col].fillna(median_by_occupation)\n\n\n\nfor col in salary_cols:\n    if col in df.columns:\n        remaining_na = df[col].isna().sum()\n        if remaining_na &gt; 0:\n            overall_median = df[col].median()\n            df[col] = df[col].fillna(overall_median)\n            print(f\"\\nFilled {remaining_na} remaining {col} NaN with overall median: {overall_median}\")\n\nprint(\"\\nFinal missing salary values:\")\nprint(f\"  SALARY: {df['SALARY'].isna().sum()}\")\nprint(f\"  SALARY_FROM: {df['SALARY_FROM'].isna().sum()}\")\nprint(f\"  SALARY_TO: {df['SALARY_TO'].isna().sum()}\")\n\n\nMissing salary values BEFORE imputation:\n  SALARY: 32833\n  SALARY_FROM: 31410\n  SALARY_TO: 31410\n\nFinal missing salary values:\n  SALARY: 0\n  SALARY_FROM: 0\n  SALARY_TO: 0\n\n\n\n\n5.2 SKILLS\n\n\nCode\nbefore = len(df)\n\ndf = df.dropna(subset=['SKILLS_NAME'])\n\nafter = len(df)\nprint(f\"Removed {before - after} rows with no skills data\")\nprint(f\"Remaining rows: {after}\")\n\n\nRemoved 447 rows with no skills data\nRemaining rows: 56773\n\n\nWe are dropping these rows since we are going to be analyze the skills required for these jobs.\n\n\n5.3 REMOTE_TYPE_NAME AND SOFTWARE_SKILLS_NAME\n\n\nCode\ncategorical_fills = {\n    'REMOTE_TYPE_NAME': 'Not Specified',\n    'SOFTWARE_SKILLS_NAME': 'Not Listed'\n}\n\nfor col, fill_value in categorical_fills.items():\n    if col in df.columns:\n        df[col] = df[col].fillna(fill_value)\n\n\n\n\n5.4 MIN_YEARS_EXPERIENCE\n\n\nCode\n#  indicator for missing experience\ndf['EXPERIENCE_SPECIFIED'] = df['MIN_YEARS_EXPERIENCE'].notna().astype(int)\n\n\ndf['MIN_YEARS_EXPERIENCE'] = df['MIN_YEARS_EXPERIENCE'].fillna(0)\n\n\nWe are not dropping thes rows, instead we are using another column to specify whether the experience was given or not, this method helps us to preserve our data since there are a lot of data points where minimum experience is not specified."
  },
  {
    "objectID": "data_cleaning.html#table-order",
    "href": "data_cleaning.html#table-order",
    "title": "Data Cleaning & Preprocessing",
    "section": "6. Table Order",
    "text": "6. Table Order\n\n\nCode\ncolumn_order = [\n    'TITLE_NAME', 'COMPANY_NAME', 'POSTED', 'DURATION',\n    'SALARY', 'SALARY_FROM', 'SALARY_TO',\n    'STATE_NAME', 'CITY_NAME',\n    'REMOTE_TYPE_NAME', 'EMPLOYMENT_TYPE_NAME',\n    'MIN_YEARS_EXPERIENCE','EXPERIENCE_SPECIFIED', 'MIN_EDULEVELS_NAME',\n    'SKILLS_NAME', 'SOFTWARE_SKILLS_NAME',\n    'SOURCE_TYPES', 'LOT_V6_OCCUPATION_NAME', 'NAICS_2022_2_NAME'\n]\ndf = df[column_order]"
  },
  {
    "objectID": "data_cleaning.html#cleaned-dataset-summary",
    "href": "data_cleaning.html#cleaned-dataset-summary",
    "title": "Data Cleaning & Preprocessing",
    "section": "7. Cleaned Dataset summary",
    "text": "7. Cleaned Dataset summary\n\n\nCode\ndf.isna().sum()\n\n\nTITLE_NAME                0\nCOMPANY_NAME              0\nPOSTED                    0\nDURATION                  0\nSALARY                    0\nSALARY_FROM               0\nSALARY_TO                 0\nSTATE_NAME                0\nCITY_NAME                 0\nREMOTE_TYPE_NAME          0\nEMPLOYMENT_TYPE_NAME      0\nMIN_YEARS_EXPERIENCE      0\nEXPERIENCE_SPECIFIED      0\nMIN_EDULEVELS_NAME        0\nSKILLS_NAME               0\nSOFTWARE_SKILLS_NAME      0\nSOURCE_TYPES              0\nLOT_V6_OCCUPATION_NAME    0\nNAICS_2022_2_NAME         0\ndtype: int64\n\n\n\n\nCode\ndf.describe()\n\n\n\n\n\n\n\n\n\nPOSTED\nDURATION\nSALARY\nSALARY_FROM\nSALARY_TO\nMIN_YEARS_EXPERIENCE\nEXPERIENCE_SPECIFIED\n\n\n\n\ncount\n56773\n56773.000000\n56773.000000\n56773.000000\n56773.000000\n56773.000000\n56773.000000\n\n\nmean\n2024-07-10 09:06:03.912423168\n35.069329\n111014.995050\n87708.293872\n128664.903229\n3.407623\n0.671270\n\n\nmin\n2024-05-01 00:00:00\n0.000000\n15860.000000\n10230.000000\n11148.000000\n0.000000\n0.000000\n\n\n25%\n2024-06-03 00:00:00\n14.000000\n95300.000000\n75600.000000\n107225.000000\n0.000000\n0.000000\n\n\n50%\n2024-07-09 00:00:00\n30.000000\n105000.000000\n81770.000000\n120750.000000\n3.000000\n1.000000\n\n\n75%\n2024-08-16 00:00:00\n60.000000\n125900.000000\n97875.000000\n150000.000000\n5.000000\n1.000000\n\n\nmax\n2024-09-30 00:00:00\n119.000000\n500000.000000\n800000.000000\n950000.000000\n15.000000\n1.000000\n\n\nstd\nNaN\n23.855804\n29957.364868\n26816.028140\n42261.703578\n3.491146\n0.469756\n\n\n\n\n\n\n\n\n\nCode\ndisplay(df.head())\n\ndf.reset_index(drop=True, inplace=True)\ndf.to_csv('data/lightcast_cleaned.csv', index=False)\n\n\n\n\n\n\n\n\n\nTITLE_NAME\nCOMPANY_NAME\nPOSTED\nDURATION\nSALARY\nSALARY_FROM\nSALARY_TO\nSTATE_NAME\nCITY_NAME\nREMOTE_TYPE_NAME\nEMPLOYMENT_TYPE_NAME\nMIN_YEARS_EXPERIENCE\nEXPERIENCE_SPECIFIED\nMIN_EDULEVELS_NAME\nSKILLS_NAME\nSOFTWARE_SKILLS_NAME\nSOURCE_TYPES\nLOT_V6_OCCUPATION_NAME\nNAICS_2022_2_NAME\n\n\n\n\n0\nEnterprise Analysts\nMurphy USA\n2024-06-02\n6\n125900.0\n97875.0\n150000.0\nArkansas\nEl Dorado, AR\nNot Specified\nFull-time (&gt; 32 hours)\n2.0\n1\nBachelor's degree\nMerchandising, Mathematics, Presentations, Pre...\nSQL (Programming Language), Power BI\nCompany\nBusiness Intelligence Analyst\nRetail Trade\n\n\n1\nOracle Consultants\nSmx Corporation Limited\n2024-06-02\n60\n125900.0\n97875.0\n150000.0\nMaine\nAugusta, ME\nRemote\nFull-time (&gt; 32 hours)\n3.0\n1\nNo Education Listed\nProcurement, Financial Statements, Oracle Busi...\nOracle Business Intelligence (BI) / OBIA, Orac...\nJob Board\nBusiness Intelligence Analyst\nAdministrative and Support and Waste Managemen...\n\n\n2\nData Analysts\nSedgwick\n2024-06-02\n35\n95300.0\n75600.0\n107225.0\nTexas\nDallas, TX\nNot Specified\nFull-time (&gt; 32 hours)\n5.0\n1\nBachelor's degree\nManagement, Exception Reporting, Report Writin...\nMicrosoft Office\nJob Board\nData / Data Mining Analyst\nFinance and Insurance\n\n\n3\nManagement Analysts\nWells Fargo\n2024-06-02\n48\n95300.0\n75600.0\n107225.0\nArizona\nPhoenix, AZ\nNot Specified\nFull-time (&gt; 32 hours)\n3.0\n1\nNo Education Listed\nExit Strategies, Reliability, User Story, Mana...\nSAS (Software), Google Cloud Platform (GCP)\nJob Board\nData / Data Mining Analyst\nFinance and Insurance\n\n\n5\nLead Data Analysts\nLumen Technologies\n2024-06-02\n10\n110155.0\n94420.0\n125890.0\nArkansas\n[Unknown City], AR\nRemote\nFull-time (&gt; 32 hours)\n0.0\n0\nBachelor's degree\nPower BI, Presentations, Data Reporting, Qlik ...\nPower BI, Qlik Sense (Data Analytics Software)...\nJob Board\nData / Data Mining Analyst\nInformation"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Business Analytics, Data Science, and Machine Learning Trends",
    "section": "",
    "text": "The demand for data science, business analytics, and machine learning professionals has grown exponentially over the past decade. As organizations increasingly rely on data-driven decision making, understanding the current job market landscape is essential for career planning.\nThis project analyzes the 2024 job market using Lightcast data to answer key questions:\n\nWhat skills are most in-demand for Data Science, Business Analytics, and ML roles?\nWhich industries are hiring the most data professionals?\nHow do salaries vary by location, experience, and skill requirements?\nWhat is the career outlook for business analytics professionals?"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Business Analytics, Data Science, and Machine Learning Trends",
    "section": "",
    "text": "The demand for data science, business analytics, and machine learning professionals has grown exponentially over the past decade. As organizations increasingly rely on data-driven decision making, understanding the current job market landscape is essential for career planning.\nThis project analyzes the 2024 job market using Lightcast data to answer key questions:\n\nWhat skills are most in-demand for Data Science, Business Analytics, and ML roles?\nWhich industries are hiring the most data professionals?\nHow do salaries vary by location, experience, and skill requirements?\nWhat is the career outlook for business analytics professionals?"
  },
  {
    "objectID": "index.html#research-rationale",
    "href": "index.html#research-rationale",
    "title": "Business Analytics, Data Science, and Machine Learning Trends",
    "section": "2 Research Rationale",
    "text": "2 Research Rationale\nThe rise of artificial intelligence and automation has transformed the labor market. Data science and machine learning roles have emerged as some of the most sought-after positions across industries. Understanding which skills employers value, which regions offer the best opportunities, and how compensation varies can help job seekers make informed career decisions.\nThis analysis takes the perspective of a job seeker entering the data science field in 2024, examining real job posting data to identify trends and opportunities."
  },
  {
    "objectID": "index.html#literature-review",
    "href": "index.html#literature-review",
    "title": "Business Analytics, Data Science, and Machine Learning Trends",
    "section": "3 Literature Review",
    "text": "3 Literature Review\nRecent research highlights the evolving nature of data science careers. According to industry reports, Python, SQL, and machine learning frameworks remain the most requested technical skills in job postings. The demand for cloud computing expertise (AWS, Azure, GCP) has also increased significantly.\nStudies show that salary disparities exist across geographic regions, with tech hubs like San Francisco, Seattle, and New York offering higher compensation. However, the rise of remote work has begun to equalize opportunities for candidates outside traditional tech centers.\nBusiness analytics roles increasingly require a blend of technical skills and domain expertise, with employers seeking candidates who can translate data insights into actionable business recommendations."
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis: Data & Analytics Job Market",
    "section": "",
    "text": "Research Question: What does the job market look like for Business Analytics, Data Science, and ML professionals in 2024?\nNarrative Flow: 1. Who’s hiring? → Top companies and industries 2. What roles exist? → Job titles within our occupation categories 3. How long do postings stay open? → Duration analysis by occupation 4. What do they want? → Skills in demand 5. What drives salary? → Key factors affecting compensation\nEach insight builds toward our ML modeling decisions.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom collections import Counter\n\npd.set_option('display.max_columns', None)\n\n# Load data\ndf = pd.read_csv('data/lightcast_cleaned.csv')\ndf['POSTED'] = pd.to_datetime(df['POSTED'])\n\n# Exclude unclassified/unknown values for cleaner analysis\ndf_clean = df[~df['NAICS_2022_2_NAME'].str.contains('Unclassified', na=False)].copy()\n\nprint(f\"Dataset: {len(df):,} job postings\")\nprint(f\"Date range: {df['POSTED'].min().strftime('%b %Y')} - {df['POSTED'].max().strftime('%b %Y')}\")\nprint(f\"Occupations: {df['LOT_V6_OCCUPATION_NAME'].nunique()}\")\n\n\nDataset: 56,773 job postings\nDate range: May 2024 - Sep 2024\nOccupations: 4\n\n\n\n\nCode\n# Top 10 Industries (excluding unclassified)\nindustry_counts = df_clean['NAICS_2022_2_NAME'].value_counts().head(10)\n\n# Top 10 Companies\ncompany_counts = df['COMPANY_NAME'].value_counts().head(10)\n\n# Create side-by-side subplots\nfig = go.Figure()\n\nfig.add_trace(go.Bar(\n    y=industry_counts.index,\n    x=industry_counts.values,\n    orientation='h',\n    marker_color='steelblue',\n    name='Industries'\n))\n\nfig.update_layout(\n    title='Top 10 Industries Hiring Data Professionals',\n    xaxis_title='Number of Job Postings',\n    yaxis={'categoryorder': 'total ascending'},\n    template='plotly_white',\n    height=450,\n    showlegend=False\n)\nfig.write_image('figures/top_industries.png', scale=2)\nfig.show()\n\n# Print top companies\nprint(\"\\nTop 10 Companies by Job Postings:\")\nfor i, (company, count) in enumerate(company_counts.items(), 1):\n    print(f\"  {i}. {company}: {count:,} postings\")\n\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nTop 10 Companies by Job Postings:\n  1. Unclassified: 3,025 postings\n  2. Deloitte: 2,352 postings\n  3. Accenture: 1,318 postings\n  4. PricewaterhouseCoopers: 697 postings\n  5. Merit America: 444 postings\n  6. Insight Global: 365 postings\n  7. Cardinal Health: 346 postings\n  8. Chewy: 319 postings\n  9. Smx Corporation Limited: 317 postings\n  10. Robert Half: 313 postings\n\n\n\n\nCode\n# Top job titles within each occupation\nfig = go.Figure()\n\ncolors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\noccupations = df['LOT_V6_OCCUPATION_NAME'].unique()\n\nfor i, occ in enumerate(occupations):\n    df_occ = df[df['LOT_V6_OCCUPATION_NAME'] == occ]\n    top_titles = df_occ['TITLE_NAME'].value_counts().head(5)\n    \n    fig.add_trace(go.Bar(\n        name=occ,\n        y=[f\"{occ[:15]}... - {title[:25]}\" for title in top_titles.index],\n        x=top_titles.values,\n        orientation='h',\n        marker_color=colors[i]\n    ))\n\nfig.update_layout(\n    title='Top 5 Job Titles per Occupation Category',\n    xaxis_title='Number of Postings',\n    yaxis={'categoryorder': 'total ascending'},\n    template='plotly_white',\n    height=600,\n    showlegend=True,\n    legend_title_text='Occupation',\n    barmode='stack'\n)\nfig.write_image('figures/job_titles_by_occupation.png', scale=2)\nfig.show()\n\n# Summary counts\nprint(\"\\nPostings per Occupation:\")\nfor occ, count in df['LOT_V6_OCCUPATION_NAME'].value_counts().items():\n    print(f\"  • {occ}: {count:,} ({count/len(df)*100:.1f}%)\")\n\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nPostings per Occupation:\n  • Data / Data Mining Analyst: 26,718 (47.1%)\n  • Business Intelligence Analyst: 26,266 (46.3%)\n  • Business / Management Analyst: 3,657 (6.4%)\n  • Market Research Analyst: 132 (0.2%)\n\n\n\n\nCode\n# Duration by Occupation\nfig = px.box(\n    df,\n    x='LOT_V6_OCCUPATION_NAME',\n    y='DURATION',\n    color='LOT_V6_OCCUPATION_NAME',\n    title='Job Posting Duration by Occupation Type',\n    labels={'LOT_V6_OCCUPATION_NAME': '', 'DURATION': 'Days Posted'}\n)\nfig.update_layout(\n    template='plotly_white',\n    showlegend=False,\n    height=450,\n    xaxis_tickangle=-15\n)\nfig.write_image('figures/duration_by_occupation.png', scale=2)\nfig.show()\n\n# Summary stats\nprint(\"\\nDuration Statistics by Occupation (days):\")\nduration_stats = df.groupby('LOT_V6_OCCUPATION_NAME')['DURATION'].agg(['median', 'mean', 'std']).round(1)\nduration_stats.columns = ['Median', 'Mean', 'Std Dev']\nprint(duration_stats.sort_values('Median'))\n\n# Overall\nprint(f\"\\nOverall median duration: {df['DURATION'].median():.0f} days\")\n\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nDuration Statistics by Occupation (days):\n                               Median  Mean  Std Dev\nLOT_V6_OCCUPATION_NAME                              \nBusiness Intelligence Analyst    30.0  34.9     24.1\nData / Data Mining Analyst       30.0  34.8     23.7\nBusiness / Management Analyst    33.0  38.1     23.3\nMarket Research Analyst          34.0  37.4     23.6\n\nOverall median duration: 30 days\n\n\n\n\nCode\n# Extract skills\ndef extract_skills(skills_series):\n    all_skills = []\n    for skills in skills_series.dropna():\n        if isinstance(skills, str) and skills not in ['Not Listed', '']:\n            all_skills.extend([s.strip() for s in skills.split(',')])\n    return Counter(all_skills)\n\n# General skills\nskill_counts = extract_skills(df['SKILLS_NAME'])\ntop_skills = pd.DataFrame(skill_counts.most_common(15), columns=['Skill', 'Count'])\ntop_skills['Percentage'] = (top_skills['Count'] / len(df) * 100).round(1)\n\n# Software skills\nsoftware_counts = extract_skills(df['SOFTWARE_SKILLS_NAME'])\ntop_software = pd.DataFrame(software_counts.most_common(10), columns=['Software', 'Count'])\ntop_software['Percentage'] = (top_software['Count'] / len(df) * 100).round(1)\n\n# Combined visualization\nfig = go.Figure()\n\nfig.add_trace(go.Bar(\n    y=top_skills['Skill'],\n    x=top_skills['Percentage'],\n    orientation='h',\n    marker_color='#2E86AB',\n    name='General Skills'\n))\n\nfig.update_layout(\n    title='Top 15 Skills in Demand (% of All Job Postings)',\n    xaxis_title='% of Postings Requiring This Skill',\n    yaxis={'categoryorder': 'total ascending'},\n    template='plotly_white',\n    height=500,\n    showlegend=False\n)\nfig.write_image('figures/top_skills.png', scale=2)\nfig.show()\n\n# Print top software\nprint(\"\\nTop 10 Software/Technical Skills:\")\nfor i, row in top_software.iterrows():\n    print(f\"  {i+1}. {row['Software']}: {row['Percentage']}%\")\n\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nTop 10 Software/Technical Skills:\n  1. SQL (Programming Language): 32.5%\n  2. Microsoft Excel: 19.7%\n  3. SAP Applications: 18.8%\n  4. Tableau (Business Intelligence Software): 18.3%\n  5. Dashboard: 18.0%\n  6. Python (Programming Language): 17.9%\n  7. Power BI: 16.7%\n  8. Microsoft Office: 11.3%\n  9. Microsoft PowerPoint: 10.7%\n  10. R (Programming Language): 9.0%\n\n\n\n\nCode\n# Salary by Occupation AND Remote Type (multi-factor view)\ndf_remote = df[df['REMOTE_TYPE_NAME'] != 'Not Specified'].copy()\n\nfig = px.box(\n    df_remote,\n    x='LOT_V6_OCCUPATION_NAME',\n    y='SALARY',\n    color='REMOTE_TYPE_NAME',\n    title='Salary by Occupation and Remote Work Type',\n    labels={\n        'LOT_V6_OCCUPATION_NAME': '',\n        'SALARY': 'Annual Salary ($)',\n        'REMOTE_TYPE_NAME': 'Work Type'\n    }\n)\nfig.update_layout(\n    template='plotly_white',\n    height=500,\n    xaxis_tickangle=-15,\n    legend_title_text='Remote Type'\n)\nfig.write_image('figures/salary_by_occupation_remote.png', scale=2)\nfig.show()\n\n# Summary table\nprint(\"\\nMedian Salary by Occupation & Remote Type:\")\npivot = df_remote.pivot_table(\n    values='SALARY',\n    index='LOT_V6_OCCUPATION_NAME',\n    columns='REMOTE_TYPE_NAME',\n    aggfunc='median'\n).round(0)\nprint(pivot.applymap(lambda x: f\"${x:,.0f}\" if pd.notna(x) else \"N/A\"))\n\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nMedian Salary by Occupation & Remote Type:\nREMOTE_TYPE_NAME              Hybrid Remote Not Remote    Remote\nLOT_V6_OCCUPATION_NAME                                          \nBusiness / Management Analyst       $97,250    $97,250   $97,250\nBusiness Intelligence Analyst      $125,900   $125,900  $125,900\nData / Data Mining Analyst          $95,300    $95,300   $95,300\nMarket Research Analyst             $94,500        N/A   $94,500\n\n\n/tmp/ipykernel_4363/976825870.py:33: FutureWarning:\n\nDataFrame.applymap has been deprecated. Use DataFrame.map instead."
  }
]